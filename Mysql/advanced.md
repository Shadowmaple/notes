# 字符集与比较规则

1.  Mysql 基本包含所有字符集

2.  GB2312和GBK是汉字字符集，占2个字节，GBK涵盖GB2312，是升级版

3.  Mysql 中的 utf8 字符集每个字符占3个字节，是阉割版的utf8字符集，真正的utf8是Mysql中的 utf8mb4，占四个字节

4.  查看字符集：

    ```sql
    show character set [like 'utf%']
    show charset [like 'utf%']
    ```

5.  比较规则包含有是否区分大小写、是否区分重音等，每个字符可有多个比较规则，且有一个默认的比较规则

6.  比较规则的作用通常体现比较字符串大小的表达式以及对某个字符串列进行排序中

7.  查看比较规则：`show collation like 'utf8%'`

8.  字符集和比较规则有服务器级、数据库级、表级和列级四个级别，均可单独设置`character set [字符集]`，`collation set [比较规则]`

9.  从客户端发送请求时的字符集转换：

    -   客户端使用操作系统字符集编码，服务器对接收的字符串采用 `character_set_client` 代表的字符集进行解码，再使用`character_set_connection`字符集编码
    -   采用`character_set_connection`进行解码，再按照具体的列的字符集进行编码。若两者的字符集相同，则无需进行字符集的转换
    -   将从某个列获取到的字节串从该列使用的字符集转换为`character_set_results`代表的字符集后发送到客户端
    -   客户端使用操作系统的字符集进行解析

10.  最好统一设置`character_set_client`、`character_set_connection`和`character_set_results`这三个系统变量的值为同一个字符集：`set names utf8`



# InnoDB的记录格式

1.  **页**是InnoDB采用的磁盘与内存交互的基本单位，一般为16kb

2.  行格式有 Compact、Redundant、Dynamic、Compressed 四种。Redundant是Mysql5.0之前的老格式，Dynamic是Mysql 5.7之后的默认行格式

3.  查看、指定和修改行格式的语法如下：

    ```sql
    show variables like '%row_format';
    create table 表名 (列的信息) row_format=行格式名称
    alter table 表名 row_format=行格式名称
    ```

4.  Compact 行格式主要分为四个部分：变长字段长度列表、NULL值列表、记录头信息、记录的真实数据。

5.  Redundant行格式主要分为三个部分：字段长度偏移列表、记录头信息、记录的真实数据。

6.  变长字段长度列表。对列中的变长类型（varchar、varbinary、text、blob）字段的实际长度，按列顺序逆序排放。

7.  每个变长字段存储所占空间为1或2个字节。仅当该可变字段允许存储的**最大字节数**超过255，并且真实存储的字节数超过127字节，使用2个字节，否则使用1个字节存储。

8.  变长字符集（如utf8、gbk）下的定长类型（如char）的长度也会被纳入变长字段长度列表中。

9.  变长字段长度列表中只存储值为 **非NULL** 的列内容占用的长度，值为 NULL 的列的长度是不储存的

10.  NULL值列表仅存储允许为NULL的字段，逆序排列。每个字段占一位，仅有0和1。值为NULL时为1，非NULL时为0。实际按照整数个字节进行存储，不满一个字节（8位）时，前面自动用0补满。

11.  记录的真实数据除了自定义的列以外，还包含有隐藏列：`row_id`（作为主键的唯一标识id，占6字节）、`transaction_id`（事务id，占6字节）、`roll_pointer`（回滚指针，占7字节）。其中`row_id`只有当未设置主键且未设置Unique键时才会自动添加。

12.  Redundant行格式的字段长度偏移列表。所有列都会存长度信息，按照字段的偏移量来存长度。对NULL值处理时，将列对应的偏移量值的第一个比特位作为是否为NULL的依据，如果为1则是NULL，否则非NULL

13.  一个行中的所有列（不包括隐藏列和记录头信息）占用的字节长度加起来不能超过65535个字节（不算Text、Blob类型的字段）

14.  行溢出数据。数据量超过16kb则会出现行溢出，本页中只保留前`768`个字节和20个字节的溢出页面地址，剩下数据分散存储到其他页

15.  不只是 VARCHAR(M) 类型的列，其他的 TEXT、BLOB 类型的列在存储数据非常多的时候也会发生行溢出

16.  相较Compact，Dynamic行格式则是将真实数据的所有字节都存储到其它页中，只在本页保留页地址；Compressed行格式在Dynamic的基础上对页采用压缩算法进行压缩

# InnoDB索引页结构

1.  页有各种不同的类型，用于存放数据的页称为索引页
2.  索引页分为7个部分：`file header`，`page header`，`Infimum + Supremum`，`User Records`，`Free Space`，`Page Directory`，`File Trailer`
3.  记录的记录头信息中，`delete_mask`表示是否删除，1为已删除。记录删除后被组成一个“垃圾链表”，所占用的空间可被重用
4.  每页会事先插入2条虚拟记录，表示最小记录和最大记录，存储在`Infimum + Supremum`部分中
5.  记录的记录头信息中，`next_record`属性表示从当前记录的真实数据到下一条记录的真实数据的地址偏移量。从而使页中的所有记录串联成一个`单链表`。
6.  规定 Infimum记录（也就是最小记录） 的下一条记录就是本页中主键值最小的用户记录，而本页中主键值最大的用户记录的下一条记录就是 Supremum记录（也就是最大记录）  
7.  `InnoDB`会把页中的记录划分为若干个组，每个组的最后一个记录的地址偏移量作为一个`槽`，存放在`Page Directory`中，所以在一个页中根据主键查找记录是非常快的，分为两步：
    +   通过二分法确定该记录所在的槽
    +   通过记录的`next_record`属性遍历该槽所在的组中的各个记录
8.  每个组最后一条记录的头信息的`n_owned`记录该组的记录数，每个分组中的记录条数规定：对于最小记录所在的分组只能有**1**条记录，最大记录所在的分组拥有的记录条数只能是 **1~8** 条，剩下的分组中记录的条数范围只能在是 **4~8** 条
9.  `File Header`部分记录本页的信息，且每个数据页的`File Header`部分都有上一个和下一个页的编号，所以所有的数据页会组成一个`双链表`。该部分各类型的页都通用。
10.  数据页结构中的文件尾部 `File Trailer`， 校验同步是否成功的用途。有校验和、日志序列位置。该部分各类型的页都通用。

|         名称         |       中文名       | 占用空间大小 |         简单描述         |
| :------------------: | :----------------: | :----------: | :----------------------: |
|    `File Header`     |      文件头部      |   `38`字节   |     页的一些通用信息     |
|    `Page Header`     |      页面头部      |   `56`字节   |   数据页专有的一些信息   |
| `Infimum + Supremum` | 最小记录和最大记录 |   `26`字节   |     两个虚拟的行记录     |
|    `User Records`    |      用户记录      |    不确定    |   实际存储的行记录内容   |
|     `Free Space`     |      空闲空间      |    不确定    |    页中尚未使用的空间    |
|   `Page Directory`   |      页面目录      |    不确定    | 页中的某些记录的相对位置 |
|    `File Trailer`    |      文件尾部      |   `8`字节    |      校验页是否完整      |

# B+树索引

1.  数据页中的记录按照主键大小顺序组成一个**单链表**，页与页之间按索引值从小到大组成**双向链表**，下一页的记录的索引值必大于上一页。
2.  当进行插入删除等操作时，不同页之间记录顺序需要调整，该过程称为**页分裂**
3.  对每个页建立索引目录，一页即一条记录，仅包含**主键值和页号**，这种记录称为**目录项记录**，在记录头信息的`record_type`属性被记为1（0为普通记录，2、3为最小和最大记录）
4.  目录项记录储存在一页中，每条目录项指向用户记录的页。多个目录页又形成索引，目录。如此，多个层级，形成一棵B+树
5.  用户记录的页都在B+树的叶子节点上，非叶子节点都是目录项记录页。最底层称为第0层，一般不会超过4层。
6.  根据主键值查找一条记录的步骤，均使用二分查找：
    1.  确定目录项记录的页
    2.  通过目录项记录的页查找到真实记录所在的页
    3.  在用户记录页中查找到记录
7.  聚簇索引（B+树），两个特点：
    -   使用记录主键值的大小进行记录和页的排序
    -   B+树的叶子节点存储的是完整的用户记录
    
8.  InnoDB会默认自动创建聚簇索引，同时在InnoDB中，聚簇索引就是数据的存储方式，也就是所谓的**索引即数据，数据即索引**
9.  二级索引，对非主键的其它列建立的索引，会形成一棵B+树，叶子节点存储的是**该列和主键**的值，目录项记录存储的是**该列值、主键值和页号**。排序根据该列的值排序，如为非唯一索引，则在列值相同时会根据主键值排序，保证目录项记录和用户记录的唯一性。
10.  根据二级索引查找时，因为存储的并非完全的用户记录，所以在找到记录时，要根据其主键值在聚簇索引进行二次查找操作，该过程称为**回表**
11.  联合索引，对多个列建立的索引，记录排序时先根据第一列排序，再根据第二列排序。本质也是二级索引，只建立一棵B+树
12.  B+树的根页面万年不动窝。
13.  一个页面最少存储2条记录
14.  MyISAM的索引方案，索引和数据分离，数据单独存在一个**数据文件**中，乱序存储，通过行号随机访问。索引存在一个**索引文件**中，为主键建立的索引也是B+树，但叶子节点存储的只是**主键值和行号**，需要根据行号在数据文件中查找相应记录。其主键索引实质也是二级索引，也需要进行一次回表操作。
15.  MyISAM的回表操作十分迅速（借助地址偏移量）。
16.  **InnoDB中的索引即数据，数据即索引，而MyISAM中却是索引是索引，数据是数据。**

# B+树索引的使用

1.  B+树的索引在时间和空间上都有代价。空间上，每建一个索引就建一棵B+树；时间上，每次对表的增删改，都可能会修改各个B+树索引记录的顺序，导致性能损耗。
2.  B+树索引适用的条件：
    -   全值匹配
    -   匹配左边的列（联合索引）
    -   匹配范围值
    -   精确匹配某一列并范围匹配另外一列（联合索引）
    -   用于排序（如联合索引，则联合索引中的各项顺序需一致，正逆序需一致）
    -   用于分组（如联合索引，则顺序需一致）
3.  适合建索引的情况：
    -   经常搜索、排序、分组的列
    -   基数大的列（列值越离散，越易于排序、查找）
    -   类型较小的列（占用空间越小，同一页中索引数越多）
    -   可以只对字符串值的前缀建立索引
    -   在表达式中索引值单独出现才会使用索引
4.  为了尽可能少的让聚簇索引发生页分裂和记录移位的情况，建议让主键拥有`AUTO_INCREMENT`属性
5.  为避免回表带来的性能损耗，建议在查询列表中只包含索引列的字段，如此便不需要回表，该操作称为**覆盖查询**。尽量使用覆盖查询。
6.  回表的代价，需要回表的记录越多，使用二级索引查找的性能就越低。因为使用查到的主键在聚簇索引查找时相对于大量记录而言是接近随机访问的，性能可能会低于全表扫描。MySQL有自带的查询优化器，*如果需要回表的记录太多则会直接使用聚簇索引进行扫描。*

# MySQL的数据目录

1.  数据目录和安装目录不一样，是专门用于存放数据的
2.  查看数据目录：`show variables like 'datadir'`
3.  每个数据库都对应一个数据目录下的子目录
4.  InnoDB用**表空间**来管理页，每个表空间都可以被划分为很多个页。表空间在物理上的概念就是一个个文件。
5.  表空间主要有**系统表空间**和**独立表空间**。MySQL5.5.7到MySQL5.6.6之间默认使用系统表空间（默认建立的文件名为`ibdata1`），即所有数据库的页都存在这一个文件中。独立表空间为每个表都有与其同名的`.ibd`文件。使用独立表空间可以很大程度上挣脱文件系统大小的限制。
6.  系统表空间和独立表空间可以在配置中设置，也可以手动相互转移
7.  MyISAM没有表空间，每个表都必定有`.MYD`和`.MYI`两个文件，`.MYD`代表数据文件，存放用户记录，`.MYI`代表索引文件，存放索引。
8.  文件系统对数据库的影响：
    +   数据库名称和表名称不得超过文件系统所允许的最大长度
    +   文件长度受文件系统最大长度限制
    +   特殊字符的处理（非拉丁字母和数字被映射为`@+编码值`）

# InnoDB的表空间

## 独立表空间

1.  **区（extent）**，用于管理页。连续64个页为一个区，默认占用1MB。每256个区归为一组。表空间是由若干个区或若干个组构成的。

2.  第一组中最开始的三个页面类型固定：`FSP_HDR`类型、`IBUF_BITMAP`类型、`INODE`类型。之后组的前两个页面类型固定：`XDES`类型、`BUF_BITMAP`类型。

3.  **碎片区（fragment）**，直属于表空间。在一个碎片区中，页的类型和目的是随意的。

4.  **段（segment）是若干完整的区和部分碎片区中零散的页的集合**。每个索引占两个段，叶子节点和非叶子节点占用两个不同的段。

5.  为某个段分配存储空间的策略：

    +   在刚开始向表中插入数据的时候，段从某个碎片区以单个页面为单位来分配存储空间
    +   当某个段已经占用了32个碎片区页面之后，就会以完整的区为单位来分配存储空间

6.  区大致可分为四类：

    +   空闲的区（FREE）
    +   有剩余空间的碎片区（FREE_FRAG）
    +   无剩余空间的碎片区（FULL_FRAG）
    +   附属于某个段的区（FSEG）

7.  `XDES Entry`结构（Extent Descriptor Entry），记录了区的一些信息和属性。。`XDES Entry`存放在表空间的每一个组的第一个页面中（第一组是`FSP_HDR`类型页，其余的是`XDES`类型页），存放256个`XDES Entry`结构，分别对应该组的256个区。

8.  `XDES Entry`之间通过`List Node`连接成一个`XDES Entry`链表

9.  直属于表空间的`XDES Entry`链表：

    +   `FREE`链表：把状态为`FREE`的区对应的`XDES Entry`结构通过`List Node`来连接成一个链表
    +   `FREE_FRAG`链表：把状态为`FREE_FRAG`的区对应的`XDES Entry`结构通过`List Node`来连接成一个链表。
    +   `FULL_FRAG`链表：把状态为`FULL_FRAG`的区对应的`XDES Entry`结构通过`List Node`来连接成一个链表。

10.  每个段有自己的三个`XDES Entry`链表：

     +   `FREE`链表：所有页面都是空闲的区对应的`XDES Entry`结构会被加入到这个链表。
     +   `NOT_FULL`链表：仍有空闲空间的区对应的`XDES Entry`结构会被加入到这个链表。
     +   `FULL`链表：无空闲空间的区对应的`XDES Entry`结构会被加入到这个链表。

11.  每个链表都对应一个一个链表基节点（`List Base Node`），`List Base Node`结构中包含有链表长度、头结点和尾节点的位置，便于迅速定位某个链表。

12.  `INODE Entry`结构，用于记录段的属性。包含段的`FREE`链表、`NOT_FULL`链表、`FULL`链表的三个基节点

13.  直属于表空间的三个`FREE`链表、`FREE_FRAG`链表、`FULL_FRAG`链表的基节点，存储在表空间的第一个页面（`FSP_HDR`）的`file space header`中

14.  每个段对应的`INODE Entry`结构会集中存放到一个类型为`INODE`的页中，如果表空间中的段特别多，则会有多个`INODE Entry`结构，可能一个页放不下，这些`INODE`类型的页会组成两种列表：

     +   `SEG_INODES_FULL`链表，该链表中的`INODE`类型的页面都已经被`INODE Entry`结构填充满了，没空闲空间存放额外的`INODE Entry`了。

     +   `SEG_INODES_FREE`链表，该链表中的`INODE`类型的页面仍有空闲空间来存放

         `INODE Entry`结构。

15.  `SEG_INODES_FULL`链表和`SEG_INODES_FREE`链表的基节点，也存放在表空间的第一个页面（`FSP_HDR`）的`file space header`中。

16.  每当我们新创建一个段（创建索引时就会创建段）时，都会创建一个`INODE Entry`结构与之对应，存储`INODE Entry`的大致过程就是这样的：

     +   先看看`SEG_INODES_FREE`链表是否为空，如果不为空，直接从该链表中获取一个节点，也就相当于获取到一个仍有空闲空间的`INODE`类型的页面，然后把该`INODE Entry`结构放到该页面中。当该页面中无剩余空间时，就把该页放到`SEG_INODES_FULL`链表中。
     +   如果`SEG_INODES_FREE`链表为空，则需要从表空间的`FREE_FRAG`链表中申请一个页面，修改该页面的类型为`INODE`，把该页面放到`SEG_INODES_FREE`链表中，与此同时把该`INODE Entry`结构放入该页面。

17.  B+数索引的根索引页中的`PAGE_BTR_SEG_LEAF`和`PAGE_BTR_SEG_TOP`两个字段，分别对应一个`Segment Header`的结构（10个字节），用于记录对应的`INODE Entry`结构的地址，用于连接索引和段。

## 系统表空间

1.  关于数据的数据、为了保存数据而额外记录的信息，称为元数据。（如该表有多少索引，每个索引对应哪几个字段，该索引对应的根页面在哪个表空间的哪个页面）
2.  InnoDB中，记录元数据的表称为内部系统表，也称为**数据字典**，都是以`B+`树的形式保存在系统表空间的某些页面中。其中`SYS_TABLES`、`SYS_COLUMNS`、`SYS_INDEXES`、`SYS_FIELDS`四张表被称为基本系统表（basic system tables）
3.  基本系统表的元数据（聚簇索引和二级索引对应的B+树位置等）存储在系统表空间页号为7的`Data Dictionary Header`页面，类型为`SYS`，记录了**数据字典**的头部信息和整个InnoDB存储引擎一些全局属性。

![](./InnoDB_file_space.png)

# 单表访问原理


1.  `MySQL`执行查询语句的方式被称为**访问方法**或**访问类型**。同一条查询语句可能有多个查询方法。MySQL优化器会自动选择最优的访问方法

2.  访问方法有：

    +   const：通过主键或唯一二级索引来定位一条记录，最多一条记录需要回表

    +   ref：使用二级索引执行查询，有多条记录需要回表，必须**等值查询**；联合索引最左边的连续索引列不全是等值比较就不能算是ref

    +   ref_or_null：二级索引等值查询的同时查询该列为NULL的记录

    +   range：使用索引（聚簇索引或二级索引）进行范围匹配

    +   index：遍历二级索引的查询；如根据联合索引的第二列值查询第一列值，此时遍历二级索引的代价低于全表扫描

    +   all：全表扫描，直接扫描聚簇索引

    +   index merge：使用多个索引完成一次查询，有`Intersection`、`Union`、`Sort-Union`三种

3.  对于包含NULL值的处理要单独思考

4.  全表扫描一般情况下是先将聚簇索引的叶子节点记录全放入内存中，再进行扫描。空间不够时会借用磁盘暂存。

5.  在有AND或OR、为某个索引确定区间范围时，会把用不到查询用不到的索引搜索条件替换为**TRUE**

6.  一般情况下只能利用单个二级索引执行查询。

7.  当有`AND`连接的多个搜索条件时可能用到`Intersection`索引合并，当有`OR`连接的多个条件时可能用到`Union`或`Sort-Union`索引合并。

8.  使用`Intersection`索引合并查询的情况：

    +   二级索引列全是等值匹配，对于联合索引，在联合索引中的每个列都必须等值匹配
    +   当同时有主键和二级索引时，二级索引必须等值匹配，而**主键列可以范围匹配**。
    +   （优化器执行的根本依据）使用单个搜索条件从二级索引中查出的数据过多，需要回表的代价大于查询多个索引的代价

9.  只有**当根据二级索引查询出的结果是按照主键值排序的**才有可能使用`Intersection`索引合并。（方便取交集，无需排序，O(n)）

10.  使用`Union`索引合并的情况：

     +   二级索引列是等值匹配，对于联合索引，在联合索引中的每个列都必须等值匹配
     +   主键列可以范围匹配
     +   使用`Intersection`索引合并的搜索条件（搜索条件的某些部分使用`Intersection`索引合并的方式得到的主键集合和其他方式得到的主键集合取交集）
     +   （根本）在单独根据搜索条件从某个二级索引中获取的记录数比较少，通过`Union`索引合并后进行访问的代价比全表扫描更小时。（OR的方式，需要全表扫描另一个过滤条件）

11.  `Sort-Union`索引合并：先按照二级索引记录的主键值进行排序，之后按照`Union`索引合并方式执行的查询方式。因为从二级索引获取的数量较少，所以排序的代价不会很高。该方式适用于如下这种情况：

     ```sql
     SELECT * FROM single_table WHERE key1 < 'a' OR key3 > 'z';
     ```

# 表连接原理

1.  连接查询算法大致有三种：**嵌套循环连接（Nested-Loop Join）、基于索引优化的查询连接、基于块的嵌套循环连接（Block Nested-Loop Join）**
2.  嵌套循环连接：先使用单表访问的最优方法获取驱动表中的结果集，遍历结果集，从被驱动表中根据连接条件查出相应数据。被驱动表的访问次数取决于驱动表的结果集数量。相当于多个嵌套循环语句。
3.  嵌套循环连接中“从驱动表中获取匹配结果再访问被驱动表的方式”实际上是，**每获取到一条驱动表记录就立即去被驱动表中找匹配的记录**，将数据加入到结果集中，而不是先获取出全部的驱动表匹配记录。
4.  基于索引优化：使用索引优化的是**被驱动表**的访问方式（使用索引），提升访问速度，其访问次数不变，仍取决于驱动表的结果集数量。
5.  在连接查询中对**被驱动表**使用**主键值或者唯一二级索引列的值**进行等值查找的查询执行方式称之为：`eq_ref`。
6.  `join buffer`：执行连接查询前申请的一块固定大小的内存。大小可通过`join_buffer_size`变量设置，默认为256KB，最小为128字节。
7.  基于块的嵌套循环连接：加入了`join buffer`的嵌套循环连接算法。
8.  基于块的嵌套循环连接原理：先把若干条**驱动表**结果集中的记录装在`join buffer`中，然后扫描**被驱动表**，每一条被驱动表的记录一次性和`join buffer`中的多条驱动表记录做匹配。因为匹配的过程都是在内存中完成的，所以在被驱动表中数据非常多的时候，可以显著减少被驱动表的`I/O`代价。
9.  嵌套循环链接是将**被驱动表**的若干记录加载到内存中，而基于块的嵌套循环连接是将**驱动表**的若干记录加载到内存中。
10.  注意：驱动表的记录并不是所有列都会被放到`join buffer`中，只有查询列表中的列和过滤条件中的列才会被放到`join buffer`中。所以将尽可能少的列作为查询列表（最好不要`*`），如此才能在`join buffer`中放置更多记录。

# 基于成本的优化

1.  一条查询语句的成本由`I/O`成本和`CPU`成本组成。

    +   `I/O`成本：从磁盘加载数据或索引到内存这个过程损耗的时间

    +   `CPU`成本：读取以及检测记录是否满足对应的搜索条件、对结果集进行排序等这些操作损耗的时间

2.  在一条语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能的方案，对比找出成本最低的方案，该方案被称为**执行计划**

3.  单表查询语句的方案选择过程：

    1.  根据搜索条件，找出可能使用的索引
    2.  计算全表扫描的代价
    3.  计算使用不同索引的代价
    4.  对比各方案，找出成本最低的一个

4.  一个查询中可能使用到的索引称之为`possible keys`

5.  MySQL在真实计算成本时会进行一些微调

6.  全表扫描成本：

    ```
    I/O成本 = 聚簇索引页面数 × 加载一个页面的成本常数 + 微调值
    CPU成本 = 表中记录数 × 访问一条记录的成本常数 + 微调值
    ```

7.  每个表都有维护一些如记录数、存储空间大小、行格式等信息，查看统计信息：`show table status like 'table1'`。其中存储的空间大小，对InnoDB来说，就是聚簇索引所占的空间大小，不包括二级索引所占空间；对MyISAM来说，就是数据文件的大小。另外注意，在InnoDB的表中，记录数是一个估计值，不是实际的记录数。

8.  使用`二级索引+回表查询`的成本：

    ```sql
    CPU成本 = 读取二级索引记录的成本 + 读取并检测回表后聚簇索引记录的成本
    	= (需读取的二级索引记录数 × 读取一条记录成本常数 + 微调值) + (待检测记录的条数 × 检测一条记录匹配条件的成本常数)
    
    I/O成本 = 范围区间的数量 + 二级索引记录数 × 一次回表成本常数
    ```

    ps：设计者将一次回表的成本等作访问一次页面的I/O成本

9.  计算某个范围区间的记录数，是通过定位左右边界的方法来计算的。

10.  通过直接访问索引对应的`B+`树来计算某个范围区间对应的索引记录条数的方式称之为`index dive`

11.  系统变量`eq_range_index_dive_limit`用于决定是否使用`index dive`的方式计算索引记录数；如果不使用，则用一种索引统计数据的方式估算

12.  查看索引的维护信息：`show index from 'table1'`。

13.  连接查询的成本由两部分组成：单次查询驱动表的成本，多次查询被驱动表的成本

14.  对驱动表进行查询后得到的记录条数称为驱动表的**扇出**（fanout）

15.  计算内连接成本时需要分析选哪一个表作为驱动表时的成本最低，即两表连接时需要分析：左表为驱动表时成本、右表为驱动表时成本。而外连接则无需如此。

16.  两表连接成本：

     ```sql
     连接查询总成本 = 单次访问驱动表的成本 + 驱动表扇出数 x 单次访问被驱动表的成本
     ```

17.  减少计算非常多种连接顺序的成本的方法：

     +   提前结束某种顺序的成本评估
     +   系统变量`optimizer_search_depth`：连接表数小于该值，就穷举分析每种连接成本，否则只分析连接表数到该值为止
     +   根据**启发式规则**不考虑某些连接顺序

18.  成本常数有server层的和engine层的。查看成本常数：

     ```sql
     use mysql;
     show tables like '%cost';
     
     select * from server_cost;
     select * from engine_cost;
     ```

19.  优化器在分析一个查询语句时，先首先执行**常量表**查询，然后把查询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本。所以对于const级别的查询，在优化阶段即可读取到数据。

# InnoDB的统计数据

1.  查看统计数据：

    ```sql
    show table status;
    show index status;
    ```
    
2.  两种存储统计数据的方式：**基于磁盘的永久性统计数据**、**基于内存的非永久性统计数据**。系统变量`innodb_stats_persistent`来控制使用何种方式存储，默认为`ON`，即永久性的。

3.  `InnoDB`默认是**以表为单位来收集和存储统计数据的**。

4.  可以单独通过`STATS_PERSISTENT`属性指定某张表的存储方式。当`STATS_PERSISTENT=1`时，表明把该表的统计数据永久地存储到磁盘上，当`STATS_PERSISTENT=0`时，表明临时地存储到内存中

5.  永久性的统计数据实际存储在`innodb_table_stats`和`innodb_index_stats`两张表里（位于mysql数据库中）。`innodb_table_stats`表中每条记录都代表一个表的统计信息（一个表一条记录），`innodb_index_stats`表中每条记录都代表一个索引的统计项（一个索引多条记录）。

6.  `innodb_table_stats`以`(database_name, table_name)`为主键，`Innodb_index_stats`以`(database_name, table_name, index_name, stat_name)`为主键。

7.  `innodb_table_stats`表中的`n_rows`统计项，即表的记录数的收集过程：按照一定算法选取几个叶子节点页面，计算每个页面中主键值记录数量，然后计算平均一个页面中主键值的记录数量乘以全部叶子节点的数量就算是该表的`n_rows`值。

8.  `n_rows`值精确与否取决于统计时采样的页面数量，名为`innodb_stats_persistent_sample_pages`的系统变量用来控制使用永久性的统计数据时，计算统计数据时采样的页面数，默认为20。也可以单独设置某个表的采样页面的数量，通过指定`STATS_SAMPLE_PAGES`属性设置。

9.  `innodb_index_stats`表中，`stat_name`表示针对该索引的统计项名称，有三种：

    +   `n_leaf_pages`：表示该索引的叶子节点占用多少页面
    +   `size`：表示该索引共占用多少页面
    +   `n_diff_pfx**NN**`：表示对应的索引列不重复的值有多少

10.  更新统计数据的方式：

     +   **自动更新**。设置`innodb_stats_auto_recalc`变量为`ON`，开启服务器自动重新计算统计数据，过程异步；每个表都维护了一个变量，记录着对该表进行增删改的记录条数，只有当发生变动的记录数量超过了表大小的**10%**，才会自动更新。
     +   **手动执行`analyze table`语句更新**。`analyze table`语句执行后会立即重新计算统计数据，过程是同步的
     +   **手动修改表的数据**。修改表中数据后，需要执行`flush table 表名;`来让查询优化器重新加载数据

11.  非永久性的统计数据采样的页面数量是由`innodb_stats_transient_sample_pages`控制的，默认值是8

12.  `innodb_stats_method`变量决定着在统计某个索引列不重复值的数量时如何对待`NULL`值。有`nulls_equal`、`nulls_unequal`和`nulls_ignored`三个候选值。

# 查询语句的优化

1.  查询优化器会基于一定的规则和策略对需要执行的MySQL语句进行一定的语句优化，即**查询重写**。

2.  查询条件的优化：去除括号、等值匹配简化、常量表达式先计算、无用的HAVING子句和WHERE子句的合并……

3.  常量表（constant tables），是通过两种方式查询花费时间特别少的表：

    +   查询的表中一条记录没有，或者只有一条记录。
    +   使用主键等值匹配或者唯一二级索引列等值匹配作为搜索条件来查询某个表。

4.  优化器在分析一个查询语句时，先首先执行常量表查询，然后把查询中涉及到该表的条件全部替换成常数，最后再分析其余表的查询成本

5.  在外连接查询中，指定的`WHERE`子句中包含被驱动表中的列不为`NULL`值的条件称之为**空值拒绝**（reject-NULL）。

6.  符合控制拒绝的外连接：会把外连接转为内连接，然后进行驱动表选择的成本评估进行优化查询。

7.  对于标量子查询或行子查询的查询语句来说，MySQL会分别独立的执行外层查询和子查询。

8.  将子查询结果集中的记录保存到临时表的过程称为**物化**（Materialize），写入临时表的记录会被去重，结果不多时使用`Memory`引擎、建立哈希索引存储，数据多时采用基于磁盘的引擎、用B+树索引存储。

9.  **半连接**（`semi-join`），MySQL内部一种执行子查询的方式。对于表1的某条记录来说，只保留表2中与之匹配的一条记录，存入结果集中。

10.  如果`IN`子查询符合转换为`semi-join`的条件，查询优化器会优先把该子查询转换为`semi-join`，然后再考虑以下5种中成本最低的半连接的执行策略，再选择成本最低的那种执行策略来执行子查询：

     +   Table pullout （子查询中的表上拉至外层`FROM`子句中）
     +   DuplicateWeedout（重复值消除）：使用临时表消除`semi-join`结果集中的重复值
     +   LooseScan（松散扫描）：扫描索引时，只区值相同的第一条记录去做匹配操作
     +   Materialization（物化）
     +   FirstMatch（首次匹配）

11.  如果`IN`子查询不符合转换为`semi-join`的条件，那么查询优化器会从下边两种策略中找出一种成本更低的方式执行子查询：

     +   先将子查询物化之后再执行查询
     +   执行`IN to EXISTS`转换

12.  如果`ANY/ALL`子查询是**不相关**子查询的话，在很多场合能转换成更好的方式去执行：

     |          原始表达式           |             转换为             |
     | :---------------------------: | :----------------------------: |
     | < ANY (SELECT inner_expr ...) | < (SELECT MAX(inner_expr) ...) |
     | > ANY (SELECT inner_expr ...) | > (SELECT MIN(inner_expr) ...) |
     | < ALL (SELECT inner_expr ...) | < (SELECT MIN(inner_expr) ...) |
     | > ALL (SELECT inner_expr ...) | > (SELECT MAX(inner_expr) ...) |

13.  在执行带有派生表的语句时，优先器会尝试把派生表和外层查询合并掉，如果不行的话，再把派生表物化掉执行查询。

# 查看执行计划

1.  在查询语句前加上`explain`，来查看查询优化器优化后的执行计划
2.  使用`explain format=json`可以看到json格式的更详细的信息，包括花费的成本。
3.  使用`explain`查看执行计划后，可以通过`show warnings`查看与这个查询的执行计划有关的一些扩展信息，如查询语句重写后的语句。
4.  `type`字段（访问方法）有以下几种，代价逐次递增：
    1.  system：当表中只有一条匹配记录且使用的存储引擎的统计数据是精确的，比如MyISAM、Memory
    2.  const
    3.  eq_ref：在连接查询时，被驱动表是通过主键或者唯一二级索引列等值匹配的方式进行访问时，对该被驱动表的访问方法
    4.  ref
    5.  fulltext：全文索引
    6.  ref_or_nul
    7.  index_merge
    8.  unique_subquery
    9.  index_subquery
    10.  range
    11.  index：索引覆盖时，对二级索引进行全部扫描
    12.  ALL
5.  使用`optimizer trace`，可以方便地展示出优化器生成执行计划的整个过程。过程分为三个阶段：prepare、optimize、execute。需要将系统变量`optimizer_trace`的`enabled`值设为`on`，才能开启此功能。

# InnoDB的Buffer Pool

1.  InnoDB会对加载到内存中的页进行缓存

2.  InnoDB在MySQL服务器启动的时候会向操作系统申请一片连续的内存，称为`Buffer Pool`（缓冲池）

3.  可以在启动服务器的时候通过配置`innodb_buffer_pool_size`参数的值来改变`Buffer Pool`的大小，默认为128M，最小值为5M。

4.  `Buffer Pool`中默认的缓存页大小和在磁盘上默认的页大小是一样的，都是16KB。每个缓存页都有一个相对应的控制块，记录了缓存页的表空间编号、页号、缓存页在`Buffer Pool`中的地址、链表节点信息、一些锁信息、`LSN`信息等等这些控制信息。

5.  控制块和缓存页都被存放到 `Buffer Pool` 中，其中控制块被存放到 `Buffer Pool` 的前边，缓存页被存放到 Buffer Pool 后边，中间未使用完、不足以创建更多的一对控制块和缓存页的空间被称为**碎片**

6.  每个控制块大约占用缓存页大小的5%，该大小不包含在`innodb_buffer_pool_size`值中，即实际申请的内存大小会比设置的参数值大5%左右。

7.  InnoDB使用了许多双向链表来管理`Buffer Pool`

8.  链表的基节点占用的内存空间并不包含在为`Buffer Pool`申请的一大片连续内存空间之内，而是单独申请的一块内存空间。包含有表头、表尾和节点数信息。

9.  **free链表**中每一个节点都代表一个空闲的缓存页，在将磁盘中的页加载到`Buffer Pool`时，会从free链表中寻找空闲的缓存页。

10.  为了快速定位某个页是否被加载到`Buffer Pool`，使用**表空间号 + 页号**作为key，缓存页作为value，建立**哈希表**。

11.  在`Buffer Pool`中某个缓存页的数据被修改，但还未更新到磁盘中，即混内存中的页和磁盘中的不一致了，该缓存页被称为**脏页**。

12.  **flush链表**用来记录各个脏页，每个节点都代表一个脏页。

13.  InnoDB有**预读**功能，就是InnoDB认为执行当前的请求可能之后会读取某些页面，就预先把它们加载到`Buffer Pool`中。有线性预读和随机预读两种方式：

     +   线性预读：如果顺序访问了某个区（`extent`）的页面超过`innodb_read_ahead_threshold`这个系统变量的值，就会触发一次异步读取下一个区中全部的页面到`Buffer Pool`的请求

     +   随机预读：如果`Buffer Pool`中已经缓存了某个区的13个连续的页面，不论这些页面是不是顺序读取的，都会触发一次`异步`读取本区中所有其的页面到`Buffer Pool`的请求。通过设置`innodb_random_read_ahead`系统变量为`ON`开启，默认不开启。

14.  为了提高**缓存命中率**，建立**LRU链表**（Least Recently Used），记录最频繁加载的页。当free链表中没有多余链表时，会将最不频繁的缓存页（位于表尾）移除，然后放入新的页到首部。每次使用到某个缓存页，就把该缓存页调整到**LRU链表**的头部。

15.  为了避免预读和全表扫描对`Buffer Pool`缓存命中率的影响，**LRU链表**分为young和old两个区域，young区域存储使用频率非常高的缓存页（热数据），old区域存储使用频率不是很高的缓存页（冷数据）。可以通过`innodb_old_blocks_pct`来调节old区域所占的比例。

16.  首次从磁盘上加载到`Buffer Pool`的页会被放到old区域的头部，在`innodb_old_blocks_time`间隔时间内访问该页不会把它移动到young区域头部。在`Buffer Pool`没有可用的空闲缓存页时，会首先淘汰掉old区域的一些页。

17.  在`Buffer Pool`特别大的时候，可以把它们拆分成若干个小的`Buffer Pool`，每个`Buffer Pool`都称为一个实例，它们都是独立的，独立的去申请内存空间，独立的管理各种链表。但总共的大小还是`innodb_buffer_pool_size`的大小。

18.  可以通过指定`innodb_buffer_pool_instances`来控制`Buffer Pool`实例的个数，每个`Buffer Pool`实例中都有各自独立的链表，互不干扰。当`innodb_buffer_pool_size`的值小于1G的时候设置多个实例是无效的，`innodb_buffer_pool_instances`会被默认修改为1

19.  MySQL 5.7.5版本之后，可以在服务器运行过程中调整`Buffer Pool`大小。每个`Buffer Pool`实例由若干个**chunk**（块）组成，每个`chunk`的大小可以在服务器启动时通过启动参数设置，在运行时不可更改，默认为128M。而在运行过程中调整`Buffer Pool`大小时，会以`chunk`为单位向操作系统申请空间。

20.  查看`Buffer Pool`的状态信息：`show engine innodb status;`

# Redo日志

1.  执行事务时会产生`redo log`
2.  redo日志会把事务在执行过程中对数据库所做的所有修改都记录下来，在之后系统崩溃重启后可以把事务所做的任何修改都恢复出来。
3.  使用redo日志的好处：占用的空间非常小，顺序写入磁盘（顺序I/O）
4.  redo日志有53种不同的类型，通用的结构为：`type`、`space ID`、`page number`、`data`
5.  一些类型的`redo`日志既包含`物理`层面的意思，也包含逻辑层面的意思：
    +   物理层面：这些日志都指明了对哪个表空间的哪个页进行了修改。
    +   逻辑层面：在系统崩溃重启时，并不能直接根据这些日志里的记载、将页面内的某个偏移量处恢复成某个数据，而是需要调用一些事先准备好的函数，执行完这些函数后才可以将页面恢复成系统崩溃前的样子
6.  在执行这些保证原子性的操作时（插入记录、页分裂等）必须以**组**的形式来记录的`redo`日志，在进行系统崩溃重启恢复时，是针对整个组中的`redo`日志进行恢复操作
7.  在每一组redo日志的最后一条后面会有一个名为`MLOG_MULTI_REC_END`的特殊redo日志，用于标识一组日志的结束。其结构只要一个`type`字段，值为31。
8.  只有一条日志时，用`type`字段的最左边一个位表示是否是一条单一的日志（1为是），而不是使用类型为`MLOG_MULTI_REC_END`的`redo`日志表示，为了节省空间。`type`字段占一个字节，右边7个比特位表示redo日志的类型。
9.  对底层页面中的一次原子访问的过程被称为一个`Mini-Transaction`，简称`mtr`。一个事务可以包含若干条语句，每一条语句其实是由若干个`mtr`组成，每一个`mtr`又可以包含若干条`redo`日志。
10.  redo日志使用单位大小为512B的页存放，存储redo日志的页可以称为block，即`redo log block`。结构分为`log block header`、`log block trailer`和`log block body`
11.  redo 日志在服务器启动时就向操作系统申请了一片连续的称为`redo log buffer`的连续内存空间，这片内存空间被划分成若干个连续的`redo log block`。其大小可以通过参数`innodb_log_buffer_size`来指定，默认为16MB。
12.  全局变量`buf_free`，指明后续写入的`redo`日志应该写入到`log buffer`中的哪个位置
13.  redo日志从内存`log buffer`刷到磁盘（日志文件）的情况：
     +   `log buffer`空间到达约1/2时
     +   事务提交时
     +   后台有一个线程，大约每秒都会刷新一次
     +   正常关闭服务器时
     +   做`checkpoint`时
14.  在MySQL的数据目录下面有一组名为`ib_logfile[n]（n=0,1,2,3...）`的redo日志文件组。写入日志文件是按照文件顺序写入的，最后的写满了就返回到第一个，就像一个循环链表。
15.  将`log buffer`中的redo日志刷新到磁盘的本质就是把block的镜像写入日志文件中，所以`redo`日志文件其实也是由若干个512字节大小的block组成。
16.  每个redo日志文件都由两部分组成：
     +   前2048个字节，即前4个block是用来存储管理信息，包含`log file header`、`checkpoint1`、`checkpoint2`三个部分，第三个block未用。
     +   从第2048字节往后用来存储`log buffer`中的block镜像。
17.  全局变量`Log Sequeue Number`，**日志序列号**，简称`LSN`，用于记录已经写入的`redo`日志量，初始值为8704
18.  统计`lsn`的增长量时，是按照实际写入的日志量加上占用的`log block header`和`log block trailer`大小来计算的。当然，若未跨多个block时，就只需计算写入的日志量。
19.  每一组由mtr生成的redo日志都有一个唯一的LSN值与其对应，LSN值越小，说明redo日志产生的越早。
20.  全局变量`buf_next_to_write`，标记当前内存`log buffer`中已经有哪些日志被刷新到磁盘中了，指向上次被刷入磁盘的日志，和`buf_free`对应。
21.  全局变量`flushed_to_disk_lsn`，表示刷新到**磁盘**中的`redo`日志量。
22.  全局变量`write_lsn`，表示刷新到**操作系统的缓冲区**中的redo日志量。
23.  当`LSN`和`flushed_to_disk_lsn`的值相同时，说明`log buffer`中的所有redo日志都已经刷新到磁盘中了。
24.  `Buffer Pool`中的flush链表（记录脏页，即被修改过的数据页），在每个控制块中都有记录两个关于页面何时修改的属性：
     +   `oldest_modification`：如果某个页面被加载到`Buffer Pool`后进行**第一次修改**，那么就将修改该页面的`mtr`**开始时**对应的`lsn`值写入这个属性。
     +   `newest_modification`：每修改一次页面，都会将修改该页面的`mtr`**结束时**对应的`lsn`值写入这个属性，也就是说该属性表示页面**最近一次修改**后对应的系统`lsn`值。
25.  `checkpoint`，覆盖原先的已刷新到磁盘中的redo日志，并将属性`checkpoint_lsn`加一的操作。两个步骤：
     1.  通过flush链表尾节点对应控制块中的`oldest_modification`属性，获取当前系统中可以被覆盖的`redo`日志对应的最大`lsn`值，小于该值的便都可以被覆盖。
     2.  将`checkpoint_lsn`和对应的`redo`日志文件组偏移量以及此次`checkpoint`的编号写到日志文件的管理信息（`checkpoint1`或`checkpoint2`）中。当`log_checkpoint_no`的值是偶数时，写到`checkpoint1`中；奇数时，写到`checkpoint2`中。
26.  查看当前`InnoDB`存储引擎中的各种`LSN`值的情况：`show engine innodb status;`
27.  可以通过修改系统变量`innodb_flush_log_at_trx_commit`的值，来改变执行事务时刷新磁盘记录的模式：
     +   0：在事务提交时不立即向磁盘中同步`redo`日志
     +   1：事务提交时立即将`redo`日志同步到磁盘，可以保证事务的持久性，默认值
     +   2：事务提交时将`redo`日志写到操作系统的缓冲区中，但并不需要保证将日志真正的刷新到磁盘
28.  使用rede日志进行恢复：
     1.  确定恢复的起始点：通过redo日志文件的`log_checkpoint_no`（做`checkpoint`的编号，在`checkpoint1`和`checkpoint2`中，取大的那一个），获取到最近发生的`checkpoint`对应的`log_checkpoint_lsn`值以及它在`redo`日志文件组中的偏移量`log_checkpoint_offset`
     2.  确定恢复的终点：通过block的`log block header`的`LOG_BLOCK_HDR_DATA_LEN`属性确定当前block是否为512（已满），未满则为终点。
     3.  使用哈希表，拉链法，通过`space ID`和`page number`计算出散列值，遍历哈希表恢复。如此相比直接遍历redo日志，避免很多读取页面的随机I/O
     4.  跳过已经刷新到磁盘的页面……
29.  `LOG_BLOCK_HDR_NO`（block的编号）的计算：`((lsn / 512) & 0x3FFFFFFFUL) + 1`。保证数量为1GB个，即redo日志文件组中包含的block块最多为1GB个。

# Undo日志

1.  在InnoDB中，记录的`insert`、`update`、`delete`都需要记录`undo log`（撤销日志）
2.  **只读**事务**第一次**对某个**临时表**进行增、删、改的操作时，或**读写**事务**第一次**对某个表（普通表和临时表）进行增、删、改的操作时，InnoDB会分配一个唯一的**事务id**
3.  事务id的生成和分配策略：
    +   服务器会在内存中维护一个全局变量，每当需要为某个事务分配一个事务id时，就会把该变量的值当作事务id分配给该事务，并且把该变量自增1。
    +   每当这个变量的值为**256的倍数**时，就会将该变量的值刷新到系统表空间的页号为**5**的页面中一个称之为`Max Trx ID`的属性处，该属性占8个字节。
    +   当系统下一次重新启动时，会将上边提到的`Max Trx ID`属性加载到内存中，将该值加上256之后赋值给我们前边提到的全局变量（因为在上次关机时该全局变量的值可能大于`Max Trx ID`属性值，比如上次的值为257，那么重新启动后加载到内存再加上256的值就是512，虽然258-511的数都没用过，但如此保证了id是唯一的，并且是递增的）
4.  聚簇索引记录中包含名为`trx_id`（事务id）和`roll_pointer`（指向undo日志的指针）的隐藏列
5.  undo日志有多种：
    +   Insert操作：类型为`TRX_UNDO_INSERT_REC`的undo日志
    +   Delete操作：类型为`TRX_UNDO_DEL_MARK_REC`的undo日志
    +   不更新主键的Update操作：类型为`TRX_UNDO_UPD_EXIST_REC`的undo日志
6.  向某个表中插入一条记录时，实际上需要向聚簇索引和所有的二级索引都插入一条记录。不过记录undo日志时，只需要考虑向聚簇索引插入记录时的情况就好了，因为其实聚簇索引记录和二级索引记录是一一对应的，在回滚插入操作时，只需要知道这条记录的主键信息，然后根据主键信息做对应的删除操作
7.  为了最大限度的节省undo日志占用的存储空间，会给undo日志中的某些属性进行压缩处理
8.  `delete mark`阶段：仅仅将记录的`delete_mask`标识位设置为1，其他的不做修改（其实会修改记录的`trx_id`、`roll_pointer`这些隐藏列的值），不将其加入到垃圾链表中。此时记录处于一个中间状态。
9.  `purge`阶段：当该删除语句所在的事务提交之后，把记录从正常链表移到垃圾链表中，由专门的线程完成。
10.  undo日志会在一条记录插入、修改、删除后，形成一条**版本链**
11.  在更新操作时，undo日志有不同的方案：
     +   **不更新主键**：当被更新的列占用的**存储空间不发生变化**时，则**就地更新**；若发生变化，则要**先删除掉旧记录，再插入新记录**，此时的删除是将其加入的垃圾链表的真正删除，而非`delete mark`操作，由用户线程完成。
     +   **更新主键**：先将旧记录进行`delete mark`操作，再根据更新后各列的值创建一条新记录，并将其插入到聚簇索引中（需重新定位插入的位置）。该情况会记录两条undo日志，一条删除时的`TRX_UNDO_DEL_MARK_REC`的undo日志，一条`TRX_UNDO_INSERT_REC`的undo日志。
12.  `undo日志`可以被分为两个大类：
     +   `TRX_UNDO_INSERT`（使用十进制1表示）：类型为`TRX_UNDO_INSERT_REC`的undo日志属于此大类，一般由`INSERT`语句产生，或者在`UPDATE`语句中有更新主键的情况也会产生此类型的undo日志。
     +   `TRX_UNDO_UPDATE`（使用十进制2表示），除了类型为`TRX_UNDO_INSERT_REC`的undo日志，其他类型的undo日志都属于这个大类，如`TRX_UNDO_DEL_MARK_REC`、`TRX_UNDO_UPD_EXIST_REC`，一般由`DELETE`、`UPDATE`语句产生的undo日志都属于这个大类。
13.  undo日志存储在类型为`FIL_PAGE_UNDO_LOG`的页面中，默认为16KB。其中包含`Undo Page Header`结构，属性如下：
     +   `TRX_UNDO_PAGE_TYPE`：存储的undo日志的类型（大类，1或2），不同大类的undo日志不能混着存储
     +   `TRX_UNDO_PAGE_START`：第一条undo日志在本页面中的起始偏移量
     +   `TRX_UNDO_PAGE_FREE`：当前最后一条undo日志结束时的偏移量
     +   `TRX_UNDO_PAGE_NODE`：代表一个`List Node`结构

14.  一个事务中的多个undo页面会连成一条链表，但insert和update类型、普通表和临时表的undo日志都要分开，所以一个事务中最多有**4**个以undo页面为节点组成的链表：普通表和临时表各有`insert undo`链表和`update undo`链表。但四条链表不是一开始都被分配好的，而是在需要的时候才即时创建。
15.  每一个Undo页面的链表都对应着一个**段**，称为`Undo Log Segment`，链表中的页面都是从这个段里边申请的。
16.  在每条undo页面链表的第一个页面（`first undo page`）中，都有一个`Undo Log Segment Header`属性，用于记录该链表对应的段的`segment header`信息（包含表空间id、页号和页中偏移量，用于定位一个`INODE Entry`）和其它关于该段的信息。
17.  一个`Undo Log Segment`可能处在的状态包括：
     +   `TRX_UNDO_ACTIVE`：活跃状态，也就是一个活跃的事务正在往这个段里边写入undo日志。
     +   `TRX_UNDO_CACHED`：被缓存的状态。处在该状态的undo页面链表等待着之后被其他事务重用。
     +   `TRX_UNDO_TO_FREE`：对于`insert undo`链表来说，如果在它对应的事务提交之后，该链表不能被重用，那么就会处于这种状态。
     +   `TRX_UNDO_TO_PURGE`：对于`update undo`链表来说，如果在它对应的事务提交之后，该链表不能被重用，那么就会处于这种状态。
     +   `TRX_UNDO_PREPARED`：包含处于`PREPARE`阶段的事务产生的`undo日志`。
18.  undo页面链表的基节点包含在`first undo page`的`undo log segment header`属性中
19.  同一个事务向一个Undo页面链表中写入的`undo日志`算是一个组，在每写入一组undo日志时，都会在`first undo page`的**Undo Log Header**属性中先记录一下关于这个组的一些属性
20.  当一个Undo页面链表**只包含一个页面**，并且该页面**已使用的空间小于整个页面空间的3/4时**，该链表会被**重用**：
     +   Insert链表重用时，会将原先的undo日志覆盖，从头写入
     +   Update链表重用时，会保留原先的undo日志，在之后的剩余空间中写入
21.  `Rollback Segment Header`页面，用于管理undo页面链表，该页面在`TRX_RSEG_UNDO_SLOTS`中存储了各个undo页面链表的`frist undo page`的页号，共1024个页号
22.  每一个`Rollback Segment Header`页面都对应着一个段，称为`Rollback Segment`（回滚段），该段中其实只有这么一个页面
23.  当事务提交时，如果该`undo slot`指向的Undo页面链表符合被重用的条件，该`undo slot`就处于被缓存的状态，被缓存的`undo slot`都会被加入到一个链表，`insert undo cached`链表或`update undo cached`链表
24.  有事务需要分配Undo页面链表时，会先从cashed链表查找是否有可重用的undo页，如无，才从回滚段的第一个`undo slot`开始，看看该`undo slot`的值是不是`FIL_NULL`，若不是，则遍历下一个
25.  当事务提交时，如果该`undo slot`指向的Undo页面链表不符合被重用的条件：
     +   对应的`Undo页面`链表是`insert undo`链表时，该`Undo页面`链表的`TRX_UNDO_STATE`属性会被设置为`TRX_UNDO_TO_FREE`，之后该Undo页面链表对应的段会被释放掉（也就意味着段中的页面可以被挪作他用），然后把该`undo slot`的值设置为`FIL_NULL`
     +   对应的Undo页面链表是`update undo`链表时，该Undo页面链表的`TRX_UNDO_STATE`属性会被设置为`TRX_UNDO_TO_PRUGE`，且会将该`undo slot`的值设置为`FIL_NULL`，然后将本次事务写入的一组undo日志放到一个**History链表**中
26.  在系统表空间的第`5`号页面中存储了128个`Rollback Segment Header`页面地址（表空间id和页号组成），每个`Rollback Segment Header`就相当于一个回滚段。在`Rollback Segment Header`页面中，包含`1024`个`undo slot`，每个`undo slot`都对应一个`Undo页面`链表。
27.  回滚段可分为两类：
     +   为**普通表**分配undo页面的段：第0号、第33-127号回滚段。第0号必须存在系统表空间中，第33-127号回滚段既可以在系统表空间中，也可在个人配置的undo表空间中
     +   为**临时表**分配undo页面的段：第1-32号回滚段。必须在临时表空间中，对应着数据目录中的`ibtmp1`文件。
28.  针对普通表和临时表划分不同种类的`回滚段`的原因：在修改针对普通表的回滚段中的Undo页面时，需要记录对应的redo日志，而修改针对临时表的回滚段中的Undo页面时，不需要记录对应的redo日志

# 事务隔离级别和MVCC

1.  为了保证多个会话（session）、多个事务访问统一数据的性能，需要略微舍弃事务的隔离性

2.  事务并发执行时会遇到的问题：

    +   脏写（Dirty Write）：一个事务**修改**了另一个**未提交**事务修改过的数据
    +   脏读（Dirty Read）：一个事务**读取**另一个**未提交**事务修改过的数据，若之前事务撤回更改，那么读取到的就是脏数据。
    +   不可重复读（Non-Repeatable Read）：一个事务**只能读取**另一个**已提交**事务修改过的数据，且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到**最新值**。
    +   幻读（Phantom）：一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入了符合这些条件的记录，原先的事务再次按照该条件查询时，**读取到了之前读取时未获取到的记录**。

3.  问题严重性：脏写 > 脏读 > 不可重复读 > 幻读

4.  SQL事务标准中有四个隔离级别：

    +   `READ UNCOMMITTED`：未提交读
    +   `READ COMMITTED`：已提交读
    +   `REPEATABLE READ`：可重复读（默认）
    +   `SERIALIZABLE`：可串行化

5.  SQL标准中不同隔离级别允许发生的问题情况：

    |     隔离级别     |     脏读     |  不可重复读  |     幻读     |
    | :--------------: | :----------: | :----------: | :----------: |
    | READ UNCOMMITTED |   Possible   |   Possible   |   Possible   |
    |  READ COMMITTED  | Not Possible |   Possible   |   Possible   |
    | REPEATABLE READ  | Not Possible | Not Possible |   Possible   |
    |   SERIALIZABLE   | Not Possible | Not Possible | Not Possible |

6.  不同的数据库厂商对SQL标准中规定的四种隔离级别支持不一样。MySQL在`REPEATABLE READ`隔离级别下，是可以选择禁止幻读问题的

7.  修改隔离级别：`set [global|session] transaction isolation level [level];`。可设置全局（global）、会话（session）和普通（不加范围关键字，表示只对下一条事务生效）。也可在启动时使用参数修改隔离级别。查看隔离级别：`show variables like 'transaction_isolation';`

8.  MVCC（Multi-Version Concurrency Control ），多版本并发控制，指的就是在使用`READ COMMITTD`、`REPEATABLE READ`这两种隔离级别的事务在执行普通的`select`操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。

9.  `READ COMMITTD`、`REPEATABLE READ`两个隔离级别的一个很大不同是生成ReadView的时机不同。`READ COMMITTD`在每一次进行普通`select`操作前都会生成一个ReadView，而`REPEATABLE  READ`只在第一次进行普通select操作前生成一个ReadView，之后的查询操作都重复使用这个ReadView。

10.  ReadView只会在select语句才会产生。

11.  ReadView中主要包含4个比较重要的内容：

     +   `m_ids`：表示在生成ReadView时当前系统中**活跃**（未提交）的读写事务的事务id列表。
     +   `min_trx_id`：表示在生成ReadView时当前系统中活跃的读写事务中最小的事务id，也就是`m_ids`中的最小值。
     +   `max_trx_id`：表示生成ReadView时系统中应该分配给下一个事务的id值。

12.  使用ReadView时，判断版本是否可见：

     +   如果被访问版本的`trx_id`属性值与`ReadView`中的`creator_trx_id`值相同，意味着当前事务在访问它自己修改过的记录，所以该版本可以被当前事务访问。
     +   如果被访问版本的`trx_id`属性值小于`ReadView`中的`min_trx_id`值，表明生成该版本的事务在当前事务生成`ReadView`前已经提交，所以该版本可以被当前事务访问。
     +   如果被访问版本的`trx_id`属性值大于或等于`ReadView`中的`max_trx_id`值，表明生成该版本的事务在当前事务生成`ReadView`后才开启，所以该版本不可以被当前事务访问。
     +   如果被访问版本的`trx_id`属性值在`ReadView`的`min_trx_id`和`max_trx_id`之间，那就需要判断一下`trx_id`属性值是不是在`m_ids`列表中，如果在，说明创建`ReadView`时生成该版本的事务还是活跃的，该版本不可以被访问；若不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

# 锁

1.  事务利用MVCC进行的读取操作称为**一致性读**（Consistent Reads）、一致性无锁读或快照读；利用锁来读取的操作称为**锁定读**（Lock Reads）
2.  锁结构存在于内存中，一条记录可以关联多个锁
3.  锁结构中包含事务信息、`is_waiting`等信息。加锁成功时`is_waiting`为false，反之为true，代表阻塞状态，需要等待前一个锁释放
4.  锁分为共享锁和独占锁：
    +   共享锁（Shared Locks），简称S锁
    +   独占锁/排他锁（Exclusive Locks），简称X锁
5.  一个记录已被加上S锁后，另一个事务还能够访问这条记录、加上S锁，但不可改动（加X锁）；被加上X锁后，不允许另一个事务对其上X或S锁
6.  根据情况，读取一条记录时，通常加上S锁，但也可能要求上X锁，来禁止其它事务的读写操作。
    +   对读取的记录加S锁：`select ... lock in share mode;`
    +   对读取的记录加X锁：`select ... for update;`。事务未提交时，其它事务读写该记录时会阻塞
7.  在插入记录时一般不加锁，而是使用一种**隐式锁**
8.  加锁的级别有**表级**和**行级**两种，分别针对表加锁和对某一记录加锁：表锁、行锁
9.  给表加S锁或X锁后的权限限制也和行锁的一样，只有S锁可相互兼容
10.  **意向锁**（Intention Locks），用于标记该**表**是否被上了S锁或X锁：
     +   **意向共享锁**（Intention Shared Lock），简称**IS锁**，对某记录上S锁时，需要先对表级别上IS锁。
     +   **意向独占锁**（Intention Exclusive Lock），简称**IE锁**，同上。
11.  IS、IX锁是表级锁，它们仅仅为了在之后加表级别的S锁和X锁时可以快速判断表中的记录是否被上锁，以避免用遍历的方式来查看表中有没有上锁的记录，其实**IS锁和IX锁是兼容的，IX锁和IX锁是兼容的**
12.  如MyISAM、Memory等不支持事务的存储类型，只有表级锁（S、X表锁），所以在select操作未完成时，会对表上S锁，此时另一会话想修改表中数据时（上X锁），就会阻塞，直到前一会话Select操作完成后才会继续执行。所以不支持事务的存储类型最好用于只读或单用户的场景下，而支持事务的存储引擎则比较适用于读写、多用户的场景。
13.  MyISAM存储引擎中有一个称之为`Concurrent Inserts`的特性，支持在对MyISAM表读取时同时插入记录，这样可以提升一些插入速度
14.  表在执行DDL语句（数据构建语句）时，其它事务相对该表进行DML（数据操纵语句）的一些select、update之类的操作时会阻塞，反之亦然。这个阻塞的过程是通过在Server层的**元数据锁**（Metadata Locks，简称MDL）实现的，不需要用到存储引擎中的锁。
15.  表级别的**AUTO-INC锁**，用于某个列添加`AUTO_INCREMENT`属性后，对该列上锁，保持其自增的特性。在单条语句执行完毕即释放该锁，而非事务结束才释放。
16.  系统实现自动给`AUTO_INCREMENT`修饰的列递增赋值的原理主要有两种：
     +   采用`AUTO-INC`锁，即在执行插入语句时就在表级别加一个`AUTO-INC`锁，然后为每条待插入记录的`AUTO_INCREMENT`修饰的列分配递增的值，在该语句执行结束后，再把`AUTO-INC`锁释放掉。
     +   采用一个**轻量级的锁**，在为插入语句生成`AUTO_INCREMENT`修饰的列的值时获取一下这个轻量级锁，然后生成本次插入语句需要用到的`AUTO_INCREMENT`列的值之后，就把该轻量级锁释放掉，并不需要等到整个插入语句执行完才释放锁。
     +   系统变量`innodb_autoinc_lock_mode`决定使用哪种方式来为`AUTO_INCREMENT`修饰的列进行赋值：0（AUTO-INC锁）、1（采用轻量级锁）、2（混合使用，插入记录数量确定时采用轻量级锁，不确定时使用`AUTO-INC`锁）
17.  行锁类型：
     +   `Record Locks`：锁上一条记录
     +   `Gap Locks`（间隙锁）：锁上两条记录间的间隔，即在该两条记录间不允许插入其它记录，避免**幻读**
     +   `Next-Key Locks`（领键锁）：既锁住一条记录，又阻止在该记录前的间隙中插入新纪录
     +   `Insert Intention Locks`（插入意向锁）：表明有事务想在某间隙中插入记录，但被`Gap Locks`所阻塞。不会阻止别的事务继续获取该记录上任何类型的锁。
     +   隐式锁：一个事务对新插入的记录可以不显式的加锁（生成一个锁结构），但是由于事务id的存在，相当于加了一个隐式锁。别的事务在对这条记录加S锁或X锁时，由于隐式锁的存在，会先帮助当前事务生成一个锁结构，然后自己再生成一个锁结构后进入等待状态。
18.  一个锁结构包含有：事务信息、索引信息、表锁/行锁信息、锁类型（行锁/表锁、锁模式（S、X、IS、IX、AUTO-INC）、行锁的具体类型）、一系列比特位（表示页面中该记录所对应的`heap_no`）、其它管理信息（哈希表和链表结构数据）。`is_waiting`等待状态包含在锁类型中。
19.  符合下边这些条件的记录在加锁时可以共用一个锁结构：
     +   在同一个事务中进行加锁操作
     +   被加锁的记录在同一个页面中
     +   加锁的类型是一样的
     +   等待状态是一样的

# 问题

1.  为什么默认一页是16kb？
2.  全文索引是怎样的
3.  InnoDB的压缩页
4.  Buffer Pool中各链表的链表基节点在哪？
5.  `row_id`和`Max Row ID`，每个表的`row_id`是怎样维护的

6.  redo日志和undo日志的作用